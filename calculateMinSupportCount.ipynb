{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "departmental-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class ARule:\n",
    "    def __init__(self,s,l,sn=0,ln=0):\n",
    "        self.s = s\n",
    "        self.l = l\n",
    "        self.sn = sn\n",
    "        self.ln = ln\n",
    "\n",
    "class Apriori:\n",
    "    def __init__(self,minSuppCount = 2,minConfidence=0.5):\n",
    "        self.df = None\n",
    "        self.file = None\n",
    "        self.basicItem = None\n",
    "        self.rawSet = None\n",
    "        self.minSuppCount = minSuppCount\n",
    "        self.minConfidence = minConfidence * 100\n",
    "        \n",
    "    def read_csv(self,file):\n",
    "        #https://stackoverflow.com/questions/27020216/import-csv-with-different-number-of-columns-per-row-using-pandas\n",
    "        df = pd.read_fwf(file, header=None)\n",
    "        df = df[0].str.split(',', expand=True)\n",
    "        self.df = df\n",
    "#         print(df)\n",
    "        #https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html\n",
    "    \n",
    "    def resolveDuplicated(self):\n",
    "        rawSet = self.df.to_numpy()\n",
    "        for nRow,row in enumerate(rawSet):\n",
    "            counter = 1\n",
    "            for nCol,col in enumerate(row):\n",
    "        #         print(row)\n",
    "        #         print(len(row))\n",
    "        #         print(col)\n",
    "                if col == None:\n",
    "                    continue\n",
    "                for restN in range(nCol+1,len(row)):\n",
    "        #             print(restN)\n",
    "                    if(col == row[restN]):\n",
    "                        row[restN] = str(col) + str(counter)\n",
    "    #                     print(f'rowID:{nRow} {col}, {row[restN]}{counter}')\n",
    "                        counter = counter + 1\n",
    "        #         print(f'{col},{nRow},{nCol}')\n",
    "        #     print('=== End each row ===')\n",
    "        self.basicItem = np.unique(rawSet[rawSet != np.array(None)])\n",
    "        self.rawSet = rawSet.astype('object')\n",
    "        return self.basicItem\n",
    "    \n",
    "    def getNextItemset(self,itemset, k):\n",
    "        basicItem = itemset\n",
    "        newBasicItem = []\n",
    "        for n,item in enumerate(basicItem):\n",
    "            for j in range(n+1,len(basicItem)):\n",
    "                item1 = item\n",
    "                item2 = basicItem[j]\n",
    "                itemSet = np.union1d(item1,item2)\n",
    "                if(len(itemSet) == k):\n",
    "                    newBasicItem.append(np.array(itemSet))\n",
    "            uniqueBasicItem = np.unique(np.array(newBasicItem),axis=0)\n",
    "            uniqueBasicItem.astype(object)\n",
    "        return uniqueBasicItem\n",
    "    \n",
    "    def calculateMinSuppCount(self,basicItem):\n",
    "        #https://stackoverflow.com/questions/56419519/selecting-rows-of-numpy-array-that-contains-all-the-given-values\n",
    "        item = basicItem\n",
    "        \n",
    "        if(type(item) == np.str):\n",
    "            k = 1\n",
    "        elif(type(item) == np.ndarray):\n",
    "            k = len(item)\n",
    "        else:\n",
    "#             print('itemset length error! line 66')\n",
    "            k = len(item)\n",
    "            \n",
    "#         print(item)\n",
    "        mask = np.isin(self.rawSet,item)\n",
    "#         print(mask.sum(axis=1))\n",
    "        vec_mask = np.isin(mask.sum(axis=1), [k])\n",
    "        ids = np.where(vec_mask)\n",
    "#         existence = ap.rawSet[ids]\n",
    "        minSuppCount = len(ids[0])\n",
    "        return minSuppCount\n",
    "    \n",
    "    def getKey(self,basicItem):\n",
    "        if(type(basicItem) == np.str):\n",
    "            return basicItem\n",
    "        elif(type(basicItem) == np.str_):\n",
    "            return basicItem\n",
    "        elif(type(basicItem) == np.ndarray):\n",
    "            return basicItem.tobytes()\n",
    "        else:\n",
    "            print('key error! line 83')\n",
    "    \n",
    "    def getMinSupportItemset(self,basicItemSet):\n",
    "        suppCountDict = {}\n",
    "        for basicItem in basicItemSet:\n",
    "            suppCountDict[self.getKey(basicItem)] = self.calculateMinSuppCount(basicItem)\n",
    "        return suppCountDict\n",
    "    \n",
    "    def filterItemsetwithCount(self,itemset,suppCountDict):\n",
    "        minSuppCount = self.minSuppCount\n",
    "        newItemset = []\n",
    "        counter = 1\n",
    "        for item in itemset:\n",
    "            count = suppCountDict[ap.getKey(item)]\n",
    "            if(count >= minSuppCount):\n",
    "                newItemset.append(item)\n",
    "        return np.array(newItemset)\n",
    "    \n",
    "    def displayItemsetCount(self,itemset,suppCountDict):\n",
    "        minSuppCount = self.minSuppCount\n",
    "        try:\n",
    "            k = itemset.shape[1]\n",
    "        except:\n",
    "            k = 1\n",
    "        counter = 1\n",
    "#         print ('{:=^40}'.format(f' {k}-ItemSet '))\n",
    "        for item in itemset:\n",
    "#             print('{:^40}'.format(f'{counter}: {item}: {suppCountDict[self.getKey(item)]}'))\n",
    "            print(f'{counter}: {item}: {suppCountDict[self.getKey(item)]}')        \n",
    "            counter = counter + 1\n",
    "            \n",
    "\n",
    "#         print ('{}'.format(f' Item that sastify min support count ({minSuppCount}) '))\n",
    "        \n",
    "#         counter = 1\n",
    "#         for item in itemset:\n",
    "#             count = suppCountDict[self.getKey(item)]\n",
    "#             if(count >= minSuppCount):\n",
    "#                 print(f'{counter}: {item}: {suppCountDict[self.getKey(item)]}')\n",
    "#                 counter = counter+1\n",
    "#         print ('{:=^40}'.format(f' End of {k}-ItemSet '))\n",
    "\n",
    "    def displayStartDivider(self,counter):\n",
    "        print('\\n')\n",
    "        print ('{:-^40}'.format(f' {counter}-itemset '))\n",
    "        print('\\n')\n",
    "#         print ('{:-^40}'.format(f'RowID: Itemset: Count'))\n",
    "    \n",
    "    def displayMinSuppCountMsg(self):\n",
    "        print('\\n')\n",
    "        print ('{:*^40}'.format(f' Item that sastify min support count ({self.minSuppCount}) '))\n",
    "        print('\\n')\n",
    "        \n",
    "    def displayFrequentPattern(self):\n",
    "        print ('{:.^40}'.format(f' Frequent Patterns '))\n",
    "        for fp in self.frequentPattern:\n",
    "            itemset = fp[0]\n",
    "            itemdict = fp[1]\n",
    "            self.displayItemsetCount(itemset,itemdict)\n",
    "            \n",
    "    def associationRule(self):\n",
    "        threeItemsetAbove = []\n",
    "        for fp in self.frequentPattern[2:]:\n",
    "            threeItemsetAbove.append(fp[0])\n",
    "            rulesSet = self.generateRules(threeItemsetAbove)\n",
    "        return threeItemsetAbove,rulesSet\n",
    "\n",
    "    # https://www.youtube.com/watch?v=9oPNGofa1pI&t=32s\n",
    "    def powerset(self,originalSet):\n",
    "        subSets = []\n",
    "        numberOfCombinations = 2 ** len(originalSet) - 1\n",
    "        for combinationIndex in range(1,numberOfCombinations):\n",
    "            subSet = []\n",
    "            for setElementIndex in range(0, len(originalSet)):\n",
    "                if combinationIndex & 1 << setElementIndex:\n",
    "                    subSet.append(originalSet[setElementIndex])\n",
    "            subSets.append(subSet)\n",
    "        return subSets    \n",
    "\n",
    "    def generateRules(self,threeItemsetAbove):\n",
    "        rulesSet = defaultdict(list)\n",
    "        for itemsets in threeItemsetAbove:\n",
    "            for itemset in itemsets:\n",
    "                subsets = self.powerset(itemset)\n",
    "                for n,subset1 in enumerate(subsets):\n",
    "                    for subset2 in subsets:\n",
    "                        sn = 0\n",
    "                        ln = 0\n",
    "                        mask = np.isin(subset1,subset2)\n",
    "                        numberOfConflict = mask.sum()\n",
    "                        if(numberOfConflict == 0):\n",
    "                            if(len(subset1) != len(subset2)):\n",
    "                                sn = self.calculateMinSuppCount(subset1)\n",
    "                                ln = self.calculateMinSuppCount(subset2+subset1)\n",
    "                                percentage = (ln/sn) * 100\n",
    "                                if (percentage >= self.minConfidence):\n",
    "                                    rulesSet[self.getKey(itemset)].append(ARule(subset1,subset2,sn,ln))\n",
    "            return rulesSet\n",
    "\n",
    "    def displayRules(self,threeItemsetAbove,rulesSet):\n",
    "        for itemsets in threeItemsetAbove:\n",
    "            for itemset in itemsets:\n",
    "                rules = rulesSet[self.getKey(itemset)]\n",
    "                print(itemset)\n",
    "                for rule in rules:\n",
    "                    percentage = (rule.ln/rule.sn) * 100\n",
    "                    print(f'{rule.s} => {rule.l} confidence={rule.ln}/{rule.sn} = {percentage}')    \n",
    "\n",
    "    def process(self,file):\n",
    "        print ('{:=^40}'.format(f' Start of apriori '))\n",
    "        self.file = file\n",
    "        self.read_csv(file)\n",
    "        self.resolveDuplicated()\n",
    "        frequentPattern = []\n",
    "\n",
    "        basicItem = self.basicItem\n",
    "        itemDict = self.getMinSupportItemset(basicItem)\n",
    "        self.itemDict = itemDict\n",
    "        # print ('{:=^40}'.format(f' 1-itemset '))\n",
    "        self.displayStartDivider(1)\n",
    "        self.displayItemsetCount(basicItem,itemDict)\n",
    "        ItemFiltered = self.filterItemsetwithCount(basicItem,itemDict)\n",
    "        # print ('{}'.format(f' Item that sastify min support count ({ap.minSuppCount}) '))\n",
    "        self.displayMinSuppCountMsg()\n",
    "        self.displayItemsetCount(ItemFiltered,itemDict)\n",
    "        frequentPattern.append([ItemFiltered,itemDict])\n",
    "        counter = 2\n",
    "        while ItemFiltered.size > 2:\n",
    "            self.displayStartDivider(counter)\n",
    "        #     print ('{:=^40}'.format(f' {counter}-itemset '))\n",
    "            nextItemset = ap.getNextItemset(ItemFiltered,counter)\n",
    "            nextItemsetCount = ap.getMinSupportItemset(nextItemset)\n",
    "            self.displayItemsetCount(nextItemset,nextItemsetCount)\n",
    "            ItemFiltered = self.filterItemsetwithCount(nextItemset,nextItemsetCount)\n",
    "            if(ItemFiltered.size != 0):\n",
    "                self.displayMinSuppCountMsg()\n",
    "            self.displayItemsetCount(ItemFiltered,nextItemsetCount)\n",
    "            counter = counter+1\n",
    "            if(ItemFiltered.size != 0):\n",
    "                frequentPattern.append([ItemFiltered,nextItemsetCount])\n",
    "        self.frequentPattern = frequentPattern\n",
    "        self.displayFrequentPattern()\n",
    "        print('')\n",
    "        print ('{:-^40}'.format(f' Strong Rule '))\n",
    "        print('')\n",
    "        try:\n",
    "            rulesSet = self.associationRule()\n",
    "            threeItemsetAbove, rulesSet = self.associationRule()\n",
    "            self.displayRules(threeItemsetAbove,rulesSet)\n",
    "        except:\n",
    "            print('\\nNo strong rule\\n')\n",
    "        # print ('{:^40}'.format(f' None '))\n",
    "        print('\\n')\n",
    "        print ('{:=^40}'.format(f' End of apriori '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blocked-choir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Start of apriori ===========\n",
      "\n",
      "\n",
      "-------------- 1-itemset ---------------\n",
      "\n",
      "\n",
      "1: I1: 6\n",
      "2: I2: 7\n",
      "3: I3: 6\n",
      "4: I4: 2\n",
      "5: I5: 2\n",
      "\n",
      "\n",
      " Item that sastify min support count (2) \n",
      "\n",
      "\n",
      "1: I1: 6\n",
      "2: I2: 7\n",
      "3: I3: 6\n",
      "4: I4: 2\n",
      "5: I5: 2\n",
      "\n",
      "\n",
      "-------------- 2-itemset ---------------\n",
      "\n",
      "\n",
      "1: ['I1' 'I2']: 4\n",
      "2: ['I1' 'I3']: 4\n",
      "3: ['I1' 'I4']: 1\n",
      "4: ['I1' 'I5']: 2\n",
      "5: ['I2' 'I3']: 4\n",
      "6: ['I2' 'I4']: 2\n",
      "7: ['I2' 'I5']: 2\n",
      "8: ['I3' 'I4']: 0\n",
      "9: ['I3' 'I5']: 1\n",
      "10: ['I4' 'I5']: 0\n",
      "\n",
      "\n",
      " Item that sastify min support count (2) \n",
      "\n",
      "\n",
      "1: ['I1' 'I2']: 4\n",
      "2: ['I1' 'I3']: 4\n",
      "3: ['I1' 'I5']: 2\n",
      "4: ['I2' 'I3']: 4\n",
      "5: ['I2' 'I4']: 2\n",
      "6: ['I2' 'I5']: 2\n",
      "\n",
      "\n",
      "-------------- 3-itemset ---------------\n",
      "\n",
      "\n",
      "1: ['I1' 'I2' 'I3']: 2\n",
      "2: ['I1' 'I2' 'I4']: 1\n",
      "3: ['I1' 'I2' 'I5']: 2\n",
      "4: ['I1' 'I3' 'I5']: 1\n",
      "5: ['I2' 'I3' 'I4']: 0\n",
      "6: ['I2' 'I3' 'I5']: 1\n",
      "7: ['I2' 'I4' 'I5']: 0\n",
      "\n",
      "\n",
      " Item that sastify min support count (2) \n",
      "\n",
      "\n",
      "1: ['I1' 'I2' 'I3']: 2\n",
      "2: ['I1' 'I2' 'I5']: 2\n",
      "\n",
      "\n",
      "-------------- 4-itemset ---------------\n",
      "\n",
      "\n",
      "1: ['I1' 'I2' 'I3' 'I5']: 1\n",
      ".......... Frequent Patterns ...........\n",
      "1: I1: 6\n",
      "2: I2: 7\n",
      "3: I3: 6\n",
      "4: I4: 2\n",
      "5: I5: 2\n",
      "1: ['I1' 'I2']: 4\n",
      "2: ['I1' 'I3']: 4\n",
      "3: ['I1' 'I5']: 2\n",
      "4: ['I2' 'I3']: 4\n",
      "5: ['I2' 'I4']: 2\n",
      "6: ['I2' 'I5']: 2\n",
      "1: ['I1' 'I2' 'I3']: 2\n",
      "2: ['I1' 'I2' 'I5']: 2\n",
      "\n",
      "------------- Strong Rule --------------\n",
      "\n",
      "['I1' 'I2' 'I3']\n",
      "['I1', 'I2'] => ['I3'] confidence=2/4 = 50.0\n",
      "['I1', 'I3'] => ['I2'] confidence=2/4 = 50.0\n",
      "['I2', 'I3'] => ['I1'] confidence=2/4 = 50.0\n",
      "['I1' 'I2' 'I5']\n",
      "['I1', 'I2'] => ['I5'] confidence=2/4 = 50.0\n",
      "['I5'] => ['I1', 'I2'] confidence=2/2 = 100.0\n",
      "['I1', 'I5'] => ['I2'] confidence=2/2 = 100.0\n",
      "['I2', 'I5'] => ['I1'] confidence=2/2 = 100.0\n",
      "\n",
      "\n",
      "============ End of apriori ============\n"
     ]
    }
   ],
   "source": [
    "file = 'item.csv'\n",
    "ap = Apriori(2,0.5)\n",
    "ap.process(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "vulnerable-aquatic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I1' 'I2' 'I3' 'I4' 'I5']\n",
      "[['I1' 'I2']\n",
      " ['I1' 'I3']\n",
      " ['I1' 'I5']\n",
      " ['I2' 'I3']\n",
      " ['I2' 'I4']\n",
      " ['I2' 'I5']]\n",
      "[['I1' 'I2' 'I3']\n",
      " ['I1' 'I2' 'I5']]\n"
     ]
    }
   ],
   "source": [
    "for fp in ap.frequentPattern:\n",
    "    itemset = fp[0]\n",
    "    itemdict = fp[1]\n",
    "    print(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "original-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "def associationRule(self):\n",
    "    threeItemsetAbove = []\n",
    "    for fp in self.frequentPattern[2:]:\n",
    "        threeItemsetAbove.append(fp[0])\n",
    "        \n",
    "    self.generateRules(threeItemsetAbove)\n",
    "    \n",
    "# https://www.youtube.com/watch?v=9oPNGofa1pI&t=32s\n",
    "def powerset(self,originalSet):\n",
    "    subSets = []\n",
    "    numberOfCombinations = 2 ** len(originalSet) - 1\n",
    "    for combinationIndex in range(1,numberOfCombinations):\n",
    "        subSet = []\n",
    "        for setElementIndex in range(0, len(originalSet)):\n",
    "            if combinationIndex & 1 << setElementIndex:\n",
    "                subSet.append(originalSet[setElementIndex])\n",
    "        subSets.append(subSet)\n",
    "    return subSets\n",
    "\n",
    "from collections import defaultdict\n",
    "rulesSet = defaultdict(list)\n",
    "\n",
    "def generateRules(self,threeItemsetAbove):\n",
    "    for itemsets in threeItemsetAbove:\n",
    "        for itemset in itemsets:\n",
    "            subsets = powerset(itemset)\n",
    "            for n,subset1 in enumerate(subsets):\n",
    "                for subset2 in subsets:\n",
    "                    sn = 0\n",
    "                    ln = 0\n",
    "                    mask = np.isin(subset1,subset2)\n",
    "                    numberOfConflict = mask.sum()\n",
    "                    if(numberOfConflict == 0):\n",
    "                        if(len(subset1) != len(subset2)):\n",
    "                            sn = ap.calculateMinSuppCount(subset1)\n",
    "                            ln = ap.calculateMinSuppCount(subset2+subset1)\n",
    "                            percentage = (ln/sn) * 100\n",
    "                            rulesSet[ap.getKey(itemset)].append(ARule(subset1,subset2,sn,ln))\n",
    "        return rulesSet\n",
    "\n",
    "def displayRules(self,threeItemsetAbove):\n",
    "    for itemsets in threeItemsetAbove:\n",
    "        for itemset in itemsets:\n",
    "            rules = rulesSet[ap.getKey(itemset)]\n",
    "            print(itemset)\n",
    "            for rule in rules:\n",
    "                percentage = (rule.ln/rule.sn) * 100\n",
    "                print(f'{rule.s} => {rule.l} confidence={rule.ln}/{rule.sn} = {percentage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-saint",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "conscious-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeItemsetAbove = []\n",
    "for fp in ap.frequentPattern[2:]:\n",
    "    threeItemsetAbove.append(fp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "written-brooks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([['I1', 'I2', 'I3'],\n",
      "       ['I1', 'I2', 'I5']], dtype='<U2')]\n"
     ]
    }
   ],
   "source": [
    "print(threeItemsetAbove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "opened-timer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I1'], ['I2'], ['I1', 'I2'], ['I3'], ['I1', 'I3'], ['I2', 'I3']]\n",
      "[['I1'], ['I2'], ['I1', 'I2'], ['I5'], ['I1', 'I5'], ['I2', 'I5']]\n"
     ]
    }
   ],
   "source": [
    "for itemsets in threeItemsetAbove:\n",
    "    for itemset in itemsets:\n",
    "        print(powerset(itemset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "suspended-mason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beer' 'Bread' 'Cola']\n",
      "['Beer'] => ['Bread', 'Cola'] confidence=2/7 = 28.57142857142857\n",
      "['Bread'] => ['Beer', 'Cola'] confidence=2/9 = 22.22222222222222\n",
      "['Beer', 'Bread'] => ['Cola'] confidence=2/6 = 33.33333333333333\n",
      "['Cola'] => ['Beer', 'Bread'] confidence=2/4 = 50.0\n",
      "['Beer', 'Cola'] => ['Bread'] confidence=2/3 = 66.66666666666666\n",
      "['Bread', 'Cola'] => ['Beer'] confidence=2/3 = 66.66666666666666\n",
      "['Beer' 'Bread' 'Diapers']\n",
      "['Beer'] => ['Bread', 'Diapers'] confidence=4/7 = 57.14285714285714\n",
      "['Bread'] => ['Beer', 'Diapers'] confidence=4/9 = 44.44444444444444\n",
      "['Beer', 'Bread'] => ['Diapers'] confidence=4/6 = 66.66666666666666\n",
      "['Diapers'] => ['Beer', 'Bread'] confidence=4/6 = 66.66666666666666\n",
      "['Beer', 'Diapers'] => ['Bread'] confidence=4/5 = 80.0\n",
      "['Bread', 'Diapers'] => ['Beer'] confidence=4/5 = 80.0\n",
      "['Beer' 'Bread' 'Milk']\n",
      "['Beer'] => ['Bread', 'Milk'] confidence=4/7 = 57.14285714285714\n",
      "['Bread'] => ['Beer', 'Milk'] confidence=4/9 = 44.44444444444444\n",
      "['Beer', 'Bread'] => ['Milk'] confidence=4/6 = 66.66666666666666\n",
      "['Milk'] => ['Beer', 'Bread'] confidence=4/8 = 50.0\n",
      "['Beer', 'Milk'] => ['Bread'] confidence=4/5 = 80.0\n",
      "['Bread', 'Milk'] => ['Beer'] confidence=4/7 = 57.14285714285714\n",
      "['Beer' 'Cola' 'Milk']\n",
      "['Beer'] => ['Cola', 'Milk'] confidence=3/7 = 42.857142857142854\n",
      "['Cola'] => ['Beer', 'Milk'] confidence=3/4 = 75.0\n",
      "['Beer', 'Cola'] => ['Milk'] confidence=3/3 = 100.0\n",
      "['Milk'] => ['Beer', 'Cola'] confidence=3/8 = 37.5\n",
      "['Beer', 'Milk'] => ['Cola'] confidence=3/5 = 60.0\n",
      "['Cola', 'Milk'] => ['Beer'] confidence=3/4 = 75.0\n",
      "['Beer' 'Diapers' 'Milk']\n",
      "['Beer'] => ['Diapers', 'Milk'] confidence=3/7 = 42.857142857142854\n",
      "['Diapers'] => ['Beer', 'Milk'] confidence=3/6 = 50.0\n",
      "['Beer', 'Diapers'] => ['Milk'] confidence=3/5 = 60.0\n",
      "['Milk'] => ['Beer', 'Diapers'] confidence=3/8 = 37.5\n",
      "['Beer', 'Milk'] => ['Diapers'] confidence=3/5 = 60.0\n",
      "['Diapers', 'Milk'] => ['Beer'] confidence=3/4 = 75.0\n",
      "['Bread' 'Cola' 'Milk']\n",
      "['Bread'] => ['Cola', 'Milk'] confidence=3/9 = 33.33333333333333\n",
      "['Cola'] => ['Bread', 'Milk'] confidence=3/4 = 75.0\n",
      "['Bread', 'Cola'] => ['Milk'] confidence=3/3 = 100.0\n",
      "['Milk'] => ['Bread', 'Cola'] confidence=3/8 = 37.5\n",
      "['Bread', 'Milk'] => ['Cola'] confidence=3/7 = 42.857142857142854\n",
      "['Cola', 'Milk'] => ['Bread'] confidence=3/4 = 75.0\n",
      "['Bread' 'Diapers' 'Milk']\n",
      "['Bread'] => ['Diapers', 'Milk'] confidence=3/9 = 33.33333333333333\n",
      "['Diapers'] => ['Bread', 'Milk'] confidence=3/6 = 50.0\n",
      "['Bread', 'Diapers'] => ['Milk'] confidence=3/5 = 60.0\n",
      "['Milk'] => ['Bread', 'Diapers'] confidence=3/8 = 37.5\n",
      "['Bread', 'Milk'] => ['Diapers'] confidence=3/7 = 42.857142857142854\n",
      "['Diapers', 'Milk'] => ['Bread'] confidence=3/4 = 75.0\n",
      "['Cola' 'Diapers' 'Milk']\n",
      "['Cola'] => ['Diapers', 'Milk'] confidence=2/4 = 50.0\n",
      "['Diapers'] => ['Cola', 'Milk'] confidence=2/6 = 33.33333333333333\n",
      "['Cola', 'Diapers'] => ['Milk'] confidence=2/2 = 100.0\n",
      "['Milk'] => ['Cola', 'Diapers'] confidence=2/8 = 25.0\n",
      "['Cola', 'Milk'] => ['Diapers'] confidence=2/4 = 50.0\n",
      "['Diapers', 'Milk'] => ['Cola'] confidence=2/4 = 50.0\n",
      "['Beer' 'Bread' 'Cola' 'Milk']\n",
      "['Beer'] => ['Bread', 'Cola'] confidence=2/7 = 28.57142857142857\n",
      "['Beer'] => ['Bread', 'Milk'] confidence=4/7 = 57.14285714285714\n",
      "['Beer'] => ['Cola', 'Milk'] confidence=3/7 = 42.857142857142854\n",
      "['Beer'] => ['Bread', 'Cola', 'Milk'] confidence=2/7 = 28.57142857142857\n",
      "['Bread'] => ['Beer', 'Cola'] confidence=2/9 = 22.22222222222222\n",
      "['Bread'] => ['Beer', 'Milk'] confidence=4/9 = 44.44444444444444\n",
      "['Bread'] => ['Cola', 'Milk'] confidence=3/9 = 33.33333333333333\n",
      "['Bread'] => ['Beer', 'Cola', 'Milk'] confidence=2/9 = 22.22222222222222\n",
      "['Beer', 'Bread'] => ['Cola'] confidence=2/6 = 33.33333333333333\n",
      "['Beer', 'Bread'] => ['Milk'] confidence=4/6 = 66.66666666666666\n",
      "['Cola'] => ['Beer', 'Bread'] confidence=2/4 = 50.0\n",
      "['Cola'] => ['Beer', 'Milk'] confidence=3/4 = 75.0\n",
      "['Cola'] => ['Bread', 'Milk'] confidence=3/4 = 75.0\n",
      "['Cola'] => ['Beer', 'Bread', 'Milk'] confidence=2/4 = 50.0\n",
      "['Beer', 'Cola'] => ['Bread'] confidence=2/3 = 66.66666666666666\n",
      "['Beer', 'Cola'] => ['Milk'] confidence=3/3 = 100.0\n",
      "['Bread', 'Cola'] => ['Beer'] confidence=2/3 = 66.66666666666666\n",
      "['Bread', 'Cola'] => ['Milk'] confidence=3/3 = 100.0\n",
      "['Beer', 'Bread', 'Cola'] => ['Milk'] confidence=2/2 = 100.0\n",
      "['Milk'] => ['Beer', 'Bread'] confidence=4/8 = 50.0\n",
      "['Milk'] => ['Beer', 'Cola'] confidence=3/8 = 37.5\n",
      "['Milk'] => ['Bread', 'Cola'] confidence=3/8 = 37.5\n",
      "['Milk'] => ['Beer', 'Bread', 'Cola'] confidence=2/8 = 25.0\n",
      "['Beer', 'Milk'] => ['Bread'] confidence=4/5 = 80.0\n",
      "['Beer', 'Milk'] => ['Cola'] confidence=3/5 = 60.0\n",
      "['Bread', 'Milk'] => ['Beer'] confidence=4/7 = 57.14285714285714\n",
      "['Bread', 'Milk'] => ['Cola'] confidence=3/7 = 42.857142857142854\n",
      "['Beer', 'Bread', 'Milk'] => ['Cola'] confidence=2/4 = 50.0\n",
      "['Cola', 'Milk'] => ['Beer'] confidence=3/4 = 75.0\n",
      "['Cola', 'Milk'] => ['Bread'] confidence=3/4 = 75.0\n",
      "['Beer', 'Cola', 'Milk'] => ['Bread'] confidence=2/3 = 66.66666666666666\n",
      "['Bread', 'Cola', 'Milk'] => ['Beer'] confidence=2/3 = 66.66666666666666\n",
      "['Beer' 'Bread' 'Diapers' 'Milk']\n",
      "['Beer'] => ['Bread', 'Diapers'] confidence=4/7 = 57.14285714285714\n",
      "['Beer'] => ['Bread', 'Milk'] confidence=4/7 = 57.14285714285714\n",
      "['Beer'] => ['Diapers', 'Milk'] confidence=3/7 = 42.857142857142854\n",
      "['Beer'] => ['Bread', 'Diapers', 'Milk'] confidence=2/7 = 28.57142857142857\n",
      "['Bread'] => ['Beer', 'Diapers'] confidence=4/9 = 44.44444444444444\n",
      "['Bread'] => ['Beer', 'Milk'] confidence=4/9 = 44.44444444444444\n",
      "['Bread'] => ['Diapers', 'Milk'] confidence=3/9 = 33.33333333333333\n",
      "['Bread'] => ['Beer', 'Diapers', 'Milk'] confidence=2/9 = 22.22222222222222\n",
      "['Beer', 'Bread'] => ['Diapers'] confidence=4/6 = 66.66666666666666\n",
      "['Beer', 'Bread'] => ['Milk'] confidence=4/6 = 66.66666666666666\n",
      "['Diapers'] => ['Beer', 'Bread'] confidence=4/6 = 66.66666666666666\n",
      "['Diapers'] => ['Beer', 'Milk'] confidence=3/6 = 50.0\n",
      "['Diapers'] => ['Bread', 'Milk'] confidence=3/6 = 50.0\n",
      "['Diapers'] => ['Beer', 'Bread', 'Milk'] confidence=2/6 = 33.33333333333333\n",
      "['Beer', 'Diapers'] => ['Bread'] confidence=4/5 = 80.0\n",
      "['Beer', 'Diapers'] => ['Milk'] confidence=3/5 = 60.0\n",
      "['Bread', 'Diapers'] => ['Beer'] confidence=4/5 = 80.0\n",
      "['Bread', 'Diapers'] => ['Milk'] confidence=3/5 = 60.0\n",
      "['Beer', 'Bread', 'Diapers'] => ['Milk'] confidence=2/4 = 50.0\n",
      "['Milk'] => ['Beer', 'Bread'] confidence=4/8 = 50.0\n",
      "['Milk'] => ['Beer', 'Diapers'] confidence=3/8 = 37.5\n",
      "['Milk'] => ['Bread', 'Diapers'] confidence=3/8 = 37.5\n",
      "['Milk'] => ['Beer', 'Bread', 'Diapers'] confidence=2/8 = 25.0\n",
      "['Beer', 'Milk'] => ['Bread'] confidence=4/5 = 80.0\n",
      "['Beer', 'Milk'] => ['Diapers'] confidence=3/5 = 60.0\n",
      "['Bread', 'Milk'] => ['Beer'] confidence=4/7 = 57.14285714285714\n",
      "['Bread', 'Milk'] => ['Diapers'] confidence=3/7 = 42.857142857142854\n",
      "['Beer', 'Bread', 'Milk'] => ['Diapers'] confidence=2/4 = 50.0\n",
      "['Diapers', 'Milk'] => ['Beer'] confidence=3/4 = 75.0\n",
      "['Diapers', 'Milk'] => ['Bread'] confidence=3/4 = 75.0\n",
      "['Beer', 'Diapers', 'Milk'] => ['Bread'] confidence=2/3 = 66.66666666666666\n",
      "['Bread', 'Diapers', 'Milk'] => ['Beer'] confidence=2/3 = 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "threeItemsetAbove = []\n",
    "for fp in ap.frequentPattern[2:]:\n",
    "    threeItemsetAbove.append(fp[0])\n",
    "    \n",
    "# https://www.youtube.com/watch?v=9oPNGofa1pI&t=32s\n",
    "def powerset(originalSet):\n",
    "    subSets = []\n",
    "    numberOfCombinations = 2 ** len(originalSet) - 1\n",
    "    for combinationIndex in range(1,numberOfCombinations):\n",
    "        subSet = []\n",
    "        for setElementIndex in range(0, len(originalSet)):\n",
    "            if combinationIndex & 1 << setElementIndex:\n",
    "                subSet.append(originalSet[setElementIndex])\n",
    "        subSets.append(subSet)\n",
    "    return subSets\n",
    "\n",
    "from collections import defaultdict\n",
    "rulesSet = defaultdict(list)\n",
    "# rulesSet = {}\n",
    "\n",
    "for itemsets in threeItemsetAbove:\n",
    "    for itemset in itemsets:\n",
    "#         print('=======')\n",
    "#         print(itemset)\n",
    "        subsets = powerset(itemset)\n",
    "        for n,subset1 in enumerate(subsets):\n",
    "            for subset2 in subsets:\n",
    "                sn = 0\n",
    "                ln = 0\n",
    "                mask = np.isin(subset1,subset2)\n",
    "                numberOfConflict = mask.sum()\n",
    "                if(numberOfConflict == 0):\n",
    "                    if(len(subset1) != len(subset2)):\n",
    "                        sn = ap.calculateMinSuppCount(subset1)\n",
    "                        ln = ap.calculateMinSuppCount(subset2+subset1)\n",
    "                        percentage = (ln/sn) * 100\n",
    "        #                 print(f'{subset1} => {subset2} confidence={ln}/{sn} = {percentage}, {subset1+subset2}')\n",
    "                        rulesSet[ap.getKey(itemset)].append(ARule(subset1,subset2,sn,ln))\n",
    "        #                 rule.append([subset1,subset2]  \n",
    "# print('==')\n",
    "# for i in rules:\n",
    "#     percentage = (i.ln/i.sn) * 100\n",
    "#     print(f'{i.s} => {i.l} confidence={i.ln}/{i.sn} = {percentage}')\n",
    "\n",
    "# for key in rulesSet:\n",
    "#     rules = rulesSet[key]\n",
    "#     print(key)\n",
    "#     for rule in rules:\n",
    "#         percentage = (rule.ln/rule.sn) * 100\n",
    "#         print(f'{rule.s} => {rule.l} confidence={rule.ln}/{rule.sn} = {percentage}')\n",
    "\n",
    "for itemsets in threeItemsetAbove:\n",
    "    for itemset in itemsets:\n",
    "        rules = rulesSet[ap.getKey(itemset)]\n",
    "        print(itemset)\n",
    "        for rule in rules:\n",
    "            percentage = (rule.ln/rule.sn) * 100\n",
    "            print(f'{rule.s} => {rule.l} confidence={rule.ln}/{rule.sn} = {percentage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "attached-humidity",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Apriori' object has no attribute 'basicItemset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-6a5fe46208f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasicItemset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitemset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Apriori' object has no attribute 'basicItemset'"
     ]
    }
   ],
   "source": [
    "ap.basicItemset(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fixed-protection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I1' 'I2' 'I5']\n"
     ]
    }
   ],
   "source": [
    "itemset = ap.frequentPattern[-1][0][1]\n",
    "print(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "geological-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['I1','I2','I3']\n",
    "b = ['I3','I1']\n",
    "c = ['I3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "behind-aggregate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "mask = np.isin(a,b)\n",
    "vec_mask = mask.sum()\n",
    "print(mask)\n",
    "print(vec_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.isin(a,b)\n",
    "#         print(mask.sum(axis=1))\n",
    "vec_mask = np.isin(mask.sum(axis=1), [k])\n",
    "ids = np.where(vec_mask)\n",
    "#         existence = ap.rawSet[ids]\n",
    "minSuppCount = len(ids[0])\n",
    "return minSuppCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "imposed-darkness",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-4efb9209caa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36many\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dm\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36many\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   2328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2329\u001b[0m     \"\"\"\n\u001b[1;32m-> 2330\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'any'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dm\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "print(np.any(b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "constant-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=9oPNGofa1pI&t=32s\n",
    "def powerset(originalSet):\n",
    "    subSets = []\n",
    "    numberOfCombinations = 2 ** len(originalSet) - 1\n",
    "    for combinationIndex in range(1,numberOfCombinations):\n",
    "        subSet = []\n",
    "        for setElementIndex in range(0, len(originalSet)):\n",
    "            if combinationIndex & 1 << setElementIndex:\n",
    "                subSet.append(originalSet[setElementIndex])\n",
    "        subSets.append(subSet)\n",
    "    return subSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "lesbian-dakota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [2],\n",
       " [1, 2],\n",
       " [3],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [1, 2, 3],\n",
       " [4],\n",
       " [1, 4],\n",
       " [2, 4],\n",
       " [1, 2, 4],\n",
       " [3, 4],\n",
       " [1, 3, 4],\n",
       " [2, 3, 4]]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powerset([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "white-thought",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I1']: 6\n",
      "['I2']: 7\n",
      "['I1', 'I2']: 4\n",
      "['I5']: 2\n",
      "['I1', 'I5']: 2\n",
      "['I2', 'I5']: 2\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/chonyy/apriori_python/blob/70c45cad9ad08cb78e57787478568d49c18c71df/apriori_python/utils.py#L77\n",
    "rules = []\n",
    "subsets = powerset(itemset)\n",
    "# print(subsets)\n",
    "for subset in subsets:\n",
    "    print(f'{subset}: {ap.calculateMinSuppCount(subset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "banner-columbus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I1']\n",
      "['I1', 'I2']\n",
      "['I1', 'I5']\n",
      "['I2']\n",
      "['I2', 'I5']\n",
      "['I5']\n"
     ]
    }
   ],
   "source": [
    "gfg = np.intersect1d(np.array(subsets,dtype=object), np.array(subsets,dtype=object)) \n",
    "    \n",
    "for i in gfg:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "stable-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARule:\n",
    "    def __init__(self,s,l,sn=0,ln=0):\n",
    "        self.s = s\n",
    "        self.l = l\n",
    "        self.sn = sn\n",
    "        self.ln = ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "brown-keyboard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.calculateMinSuppCount(['I2','I5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "inclusive-speaking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I1' 'I2' 'I5' None]\n",
      " ['I2' 'I4' None None]\n",
      " ['I2' 'I3' None None]\n",
      " ['I1' 'I2' 'I4' None]\n",
      " ['I1' 'I3' None None]\n",
      " ['I2' 'I3' None None]\n",
      " ['I1' 'I3' None None]\n",
      " ['I1' 'I2' 'I3' 'I5']\n",
      " ['I1' 'I2' 'I3' None]]\n"
     ]
    }
   ],
   "source": [
    "print(ap.rawSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "healthy-nancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I1'] => ['I2', 'I5'] confidence=2/6 = 33.33333333333333\n",
      "['I2'] => ['I1', 'I5'] confidence=2/7 = 28.57142857142857\n",
      "['I1', 'I2'] => ['I5'] confidence=2/4 = 50.0\n",
      "['I5'] => ['I1', 'I2'] confidence=2/2 = 100.0\n",
      "['I1', 'I5'] => ['I2'] confidence=2/2 = 100.0\n",
      "['I2', 'I5'] => ['I1'] confidence=2/2 = 100.0\n"
     ]
    }
   ],
   "source": [
    "rule = []\n",
    "for n,subset1 in enumerate(subsets):\n",
    "    for subset2 in subsets:\n",
    "        sn = 0\n",
    "        ln = 0\n",
    "        mask = np.isin(subset1,subset2)\n",
    "        numberOfConflict = mask.sum()\n",
    "        if(numberOfConflict == 0):\n",
    "            if(len(subset1) != len(subset2)):\n",
    "                sn = ap.calculateMinSuppCount(subset1)\n",
    "                ln = ap.calculateMinSuppCount(subset2+subset1)\n",
    "                percentage = (ln/sn) * 100\n",
    "#                 print(f'{subset1} => {subset2} confidence={ln}/{sn} = {percentage}, {subset1+subset2}')\n",
    "                rule.append(ARule(subset1,subset2,sn,ln))\n",
    "#                 rule.append([subset1,subset2]  \n",
    "# print('==')\n",
    "for i in rule:\n",
    "    percentage = (i.ln/i.sn) * 100\n",
    "    print(f'{i.s} => {i.l} confidence={i.ln}/{i.sn} = {percentage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "trying-alfred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I1' 'I2' 'I3']\n",
      " ['I1' 'I2' 'I5']]\n"
     ]
    }
   ],
   "source": [
    "itemset = ap.frequentPattern[-1][0]\n",
    "print(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "therapeutic-stable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I1' 'I2' 'I3']\n",
      "['I1' 'I2' 'I5']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "rulesSet = defaultdict(list)\n",
    "# rulesSet = {}\n",
    "for itemset in ap.frequentPattern[-1][0]:\n",
    "    print(itemset)\n",
    "    subsets = powerset(itemset)\n",
    "    for n,subset1 in enumerate(subsets):\n",
    "        for subset2 in subsets:\n",
    "            sn = 0\n",
    "            ln = 0\n",
    "            mask = np.isin(subset1,subset2)\n",
    "            numberOfConflict = mask.sum()\n",
    "            if(numberOfConflict == 0):\n",
    "                if(len(subset1) != len(subset2)):\n",
    "                    sn = ap.calculateMinSuppCount(subset1)\n",
    "                    ln = ap.calculateMinSuppCount(subset2+subset1)\n",
    "                    percentage = (ln/sn) * 100\n",
    "    #                 print(f'{subset1} => {subset2} confidence={ln}/{sn} = {percentage}, {subset1+subset2}')\n",
    "                    rulesSet[ap.getKey(itemset)].append(ARule(subset1,subset2,sn,ln))\n",
    "    #                 rule.append([subset1,subset2]  \n",
    "# print('==')\n",
    "# for i in rules:\n",
    "#     percentage = (i.ln/i.sn) * 100\n",
    "#     print(f'{i.s} => {i.l} confidence={i.ln}/{i.sn} = {percentage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "expected-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'I\\x00\\x00\\x001\\x00\\x00\\x00I\\x00\\x00\\x002\\x00\\x00\\x00I\\x00\\x00\\x003\\x00\\x00\\x00'\n",
      "['I1'] => ['I2', 'I3'] confidence=2/6 = 33.33333333333333\n",
      "['I2'] => ['I1', 'I3'] confidence=2/7 = 28.57142857142857\n",
      "['I1', 'I2'] => ['I3'] confidence=2/4 = 50.0\n",
      "['I3'] => ['I1', 'I2'] confidence=2/6 = 33.33333333333333\n",
      "['I1', 'I3'] => ['I2'] confidence=2/4 = 50.0\n",
      "['I2', 'I3'] => ['I1'] confidence=2/4 = 50.0\n",
      "b'I\\x00\\x00\\x001\\x00\\x00\\x00I\\x00\\x00\\x002\\x00\\x00\\x00I\\x00\\x00\\x005\\x00\\x00\\x00'\n",
      "['I1'] => ['I2', 'I5'] confidence=2/6 = 33.33333333333333\n",
      "['I2'] => ['I1', 'I5'] confidence=2/7 = 28.57142857142857\n",
      "['I1', 'I2'] => ['I5'] confidence=2/4 = 50.0\n",
      "['I5'] => ['I1', 'I2'] confidence=2/2 = 100.0\n",
      "['I1', 'I5'] => ['I2'] confidence=2/2 = 100.0\n",
      "['I2', 'I5'] => ['I1'] confidence=2/2 = 100.0\n"
     ]
    }
   ],
   "source": [
    "for key in rulesSet:\n",
    "    rules = rulesSet[key]\n",
    "    print(key)\n",
    "    for rule in rules:\n",
    "        percentage = (rule.ln/rule.sn) * 100\n",
    "        print(f'{rule.s} => {rule.l} confidence={rule.ln}/{rule.sn} = {percentage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "single-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "for itemset in rulesSet:\n",
    "    rule = rulesSet[itemset]\n",
    "    print(itemset)\n",
    "    for r in rule:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "sublime-network",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'I\\x00\\x00\\x001\\x00\\x00\\x00I\\x00\\x00\\x002\\x00\\x00\\x00I\\x00\\x00\\x003\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(itemset.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "public-carbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I1', 'I2', 'I5']\n"
     ]
    }
   ],
   "source": [
    "print(rule[-1].l+(rule[-1].s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "centered-ladder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = rule[-1].l\n",
    "ap.calculateMinSuppCount(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "corresponding-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I1', 'I2', 'I3'], dtype='<U2')"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "nervous-morrison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.calculateMinSuppCount(rule[-1].s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "educational-match",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['I2', 'I5']\n"
     ]
    }
   ],
   "source": [
    "print(ap.calculateMinSuppCount(subsets[-1]))\n",
    "print(subsets[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "urban-costs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.ARule object at 0x0000016BFE746430>\n",
      "<__main__.ARule object at 0x0000016BFE746100>\n",
      "<__main__.ARule object at 0x0000016BFE7469D0>\n",
      "<__main__.ARule object at 0x0000016BFE7465B0>\n",
      "<__main__.ARule object at 0x0000016BFE7463A0>\n",
      "<__main__.ARule object at 0x0000016BFE746BB0>\n"
     ]
    }
   ],
   "source": [
    "for i in rule:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "responsible-guard",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-2ecf17998b5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma_p1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma_p2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubsets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcartesian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcartesian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma_p1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_p2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "a_p1 = a_p2 = subsets\n",
    "from sklearn.utils.extmath import cartesian\n",
    "print(cartesian([a_p1, a_p2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "permanent-career",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[list(['I1']) list(['I1'])]\n",
      " [list(['I2']) list(['I2'])]\n",
      " [list(['I1', 'I2']) list(['I1', 'I2'])]\n",
      " [list(['I5']) list(['I5'])]\n",
      " [list(['I1', 'I5']) list(['I1', 'I5'])]\n",
      " [list(['I2', 'I5']) list(['I2', 'I5'])]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-230-9defcb399a82>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  z = np.array(list(zip(subsets, subsets)))\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/44409084/how-to-zip-two-1d-numpy-array-to-2d-numpy-array\n",
    "# https://www.mathsisfun.com/sets/symbols.html\n",
    "z = np.array(list(zip(subsets, subsets)))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "sexual-extension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[list(['I1']) list(['I1'])]\n",
      " [list(['I2']) list(['I1'])]\n",
      " [list(['I1', 'I2']) list(['I1'])]\n",
      " [list(['I5']) list(['I1'])]\n",
      " [list(['I1', 'I5']) list(['I1'])]\n",
      " [list(['I2', 'I5']) list(['I1'])]\n",
      " [list(['I1']) list(['I2'])]\n",
      " [list(['I2']) list(['I2'])]\n",
      " [list(['I1', 'I2']) list(['I2'])]\n",
      " [list(['I5']) list(['I2'])]\n",
      " [list(['I1', 'I5']) list(['I2'])]\n",
      " [list(['I2', 'I5']) list(['I2'])]\n",
      " [list(['I1']) list(['I1', 'I2'])]\n",
      " [list(['I2']) list(['I1', 'I2'])]\n",
      " [list(['I1', 'I2']) list(['I1', 'I2'])]\n",
      " [list(['I5']) list(['I1', 'I2'])]\n",
      " [list(['I1', 'I5']) list(['I1', 'I2'])]\n",
      " [list(['I2', 'I5']) list(['I1', 'I2'])]\n",
      " [list(['I1']) list(['I5'])]\n",
      " [list(['I2']) list(['I5'])]\n",
      " [list(['I1', 'I2']) list(['I5'])]\n",
      " [list(['I5']) list(['I5'])]\n",
      " [list(['I1', 'I5']) list(['I5'])]\n",
      " [list(['I2', 'I5']) list(['I5'])]\n",
      " [list(['I1']) list(['I1', 'I5'])]\n",
      " [list(['I2']) list(['I1', 'I5'])]\n",
      " [list(['I1', 'I2']) list(['I1', 'I5'])]\n",
      " [list(['I5']) list(['I1', 'I5'])]\n",
      " [list(['I1', 'I5']) list(['I1', 'I5'])]\n",
      " [list(['I2', 'I5']) list(['I1', 'I5'])]\n",
      " [list(['I1']) list(['I2', 'I5'])]\n",
      " [list(['I2']) list(['I2', 'I5'])]\n",
      " [list(['I1', 'I2']) list(['I2', 'I5'])]\n",
      " [list(['I5']) list(['I2', 'I5'])]\n",
      " [list(['I1', 'I5']) list(['I2', 'I5'])]\n",
      " [list(['I2', 'I5']) list(['I2', 'I5'])]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/11144513/cartesian-product-of-x-and-y-array-points-into-single-array-of-2d-points\n",
    "x = y = subsets\n",
    "z= np.transpose([np.tile(x, len(y)), np.repeat(y, len(x))])\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "catholic-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = []\n",
    "for i in z:\n",
    "    s = i[0]\n",
    "    l = i[1]\n",
    "    mask = np.isin(s,l)\n",
    "    mask2 = np.isin(l,s)\n",
    "    vec_mask = mask.sum()\n",
    "    vec_mask2 = mask2.sum()\n",
    "    if(vec_mask == 0 and vec_mask2 == 0):\n",
    "        v.append([s,l])\n",
    "v = np.array(v,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "heavy-synthetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['I2']) list(['I1'])]\n",
      "[list(['I5']) list(['I1'])]\n",
      "[list(['I2', 'I5']) list(['I1'])]\n",
      "[list(['I1']) list(['I2'])]\n",
      "[list(['I5']) list(['I2'])]\n",
      "[list(['I1', 'I5']) list(['I2'])]\n",
      "[list(['I5']) list(['I1', 'I2'])]\n",
      "[list(['I1']) list(['I5'])]\n",
      "[list(['I2']) list(['I5'])]\n",
      "[list(['I1', 'I2']) list(['I5'])]\n",
      "[list(['I2']) list(['I1', 'I5'])]\n",
      "[list(['I1']) list(['I2', 'I5'])]\n"
     ]
    }
   ],
   "source": [
    "for i in v:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "demanding-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['I1'],)\n",
      "(['I2'],)\n",
      "(['I1', 'I2'],)\n",
      "(['I5'],)\n",
      "(['I1', 'I5'],)\n",
      "(['I2', 'I5'],)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for element in itertools.product(subsets):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "premier-channel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['I5']) list(['I1'])]\n"
     ]
    }
   ],
   "source": [
    "print(z[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "warming-campaign",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I1'] ['I1']\n",
      "['I2'] ['I2']\n",
      "['I1', 'I2'] ['I1', 'I2']\n",
      "['I5'] ['I5']\n",
      "['I1', 'I5'] ['I1', 'I5']\n",
      "['I2', 'I5'] ['I2', 'I5']\n"
     ]
    }
   ],
   "source": [
    "for x,y in z:\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "agricultural-grill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I1' 'I2' 'I5']\n"
     ]
    }
   ],
   "source": [
    "print(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "lonely-spine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I1', 'I2', 'I3'], dtype='<U2')"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-gardening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "realistic-engagement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: I1: 6\n",
      "2: I2: 7\n",
      "3: I3: 6\n",
      "4: I4: 2\n",
      "5: I5: 2\n",
      "1: ['I1' 'I2']: 4\n",
      "2: ['I1' 'I3']: 4\n",
      "3: ['I1' 'I5']: 2\n",
      "4: ['I2' 'I3']: 4\n",
      "5: ['I2' 'I4']: 2\n",
      "6: ['I2' 'I5']: 2\n",
      "1: ['I1' 'I2' 'I3']: 2\n",
      "2: ['I1' 'I2' 'I5']: 2\n"
     ]
    }
   ],
   "source": [
    "for fp in ap.frequentPattern:\n",
    "    itemset = fp[0]\n",
    "    itemdict = fp[1]\n",
    "    ap.displayItemsetCount(itemset,itemdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "analyzed-genome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I1' 'I2' 'I3']\n",
      " ['I1' 'I2' 'I5']]\n"
     ]
    }
   ],
   "source": [
    "fp = ap.frequentPattern[-1]\n",
    "itemset = fp[0]\n",
    "itemdict = fp[1]\n",
    "print(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "southeast-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "invalid-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classical_recursive_two(elems):\n",
    "    \"\"\" Given a list of elements return a generator \n",
    "    that will generate all the subsets\"\"\"\n",
    "    if  len(elems) <= 1:\n",
    "        yield elems\n",
    "        yield []\n",
    "    else:\n",
    "        for item in classical_recursive_two(elems[1:]):\n",
    "            yield [elems[0]] + item\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "corporate-budget",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['I1', 'I2', 'I3'],\n",
       "       ['I1', 'I2', 'I5']], dtype='<U2')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "daily-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://codereview.stackexchange.com/questions/147633/get-subsets-of-a-set-given-as-a-list\n",
    "#https://www.youtube.com/watch?v=9oPNGofa1pI\n",
    "def subsets(s):\n",
    "    \"\"\"\n",
    "    :type s: list[]\n",
    "    \"\"\"\n",
    "    sets = []\n",
    "    for i in range(2**len(s)):\n",
    "        subset = []\n",
    "        for j in range(len(s)):\n",
    "            if i & (1 << j) > 0:\n",
    "                subset.append(s[j])\n",
    "        sets.append(subset)\n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "current-madonna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['I1'], ['I2'], ['I1', 'I2'], ['I3'], ['I1', 'I3'], ['I2', 'I3'], ['I1', 'I2', 'I3']]\n"
     ]
    }
   ],
   "source": [
    "print(subsets(itemset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "interpreted-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://codereview.stackexchange.com/questions/147633/get-subsets-of-a-set-given-as-a-list\n",
    "#https://www.youtube.com/watch?v=9oPNGofa1pI\n",
    "#https://www.mathsisfun.com/sets/power-set.html\n",
    "def subsetssss(s):\n",
    "    \"\"\"\n",
    "    :type s: list[]\n",
    "    \"\"\"\n",
    "    sets = []\n",
    "    for i in range(2**len(s)):\n",
    "        subset = []\n",
    "        for j in range(len(s)):\n",
    "            if i & (1 << j) > 0:\n",
    "                print(s[j])\n",
    "                subset.append(s[j])\n",
    "        sets.append(subset)\n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "stock-mauritius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "c\n",
      "b\n",
      "c\n",
      "l\n",
      "b\n",
      "l\n",
      "c\n",
      "l\n",
      "b\n",
      "c\n",
      "l\n",
      "s\n",
      "b\n",
      "s\n",
      "c\n",
      "s\n",
      "b\n",
      "c\n",
      "s\n",
      "l\n",
      "s\n",
      "b\n",
      "l\n",
      "s\n",
      "c\n",
      "l\n",
      "s\n",
      "b\n",
      "c\n",
      "l\n",
      "s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['b'],\n",
       " ['c'],\n",
       " ['b', 'c'],\n",
       " ['l'],\n",
       " ['b', 'l'],\n",
       " ['c', 'l'],\n",
       " ['b', 'c', 'l'],\n",
       " ['s'],\n",
       " ['b', 's'],\n",
       " ['c', 's'],\n",
       " ['b', 'c', 's'],\n",
       " ['l', 's'],\n",
       " ['b', 'l', 's'],\n",
       " ['c', 'l', 's'],\n",
       " ['b', 'c', 'l', 's']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsetssss(['b','c','l','s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "tough-classification",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-d4f43103af67>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array(subsets(itemset[0]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([]), list(['I1']), list(['I2']), list(['I1', 'I2']),\n",
       "       list(['I3']), list(['I1', 'I3']), list(['I2', 'I3']),\n",
       "       list(['I1', 'I2', 'I3'])], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(subsets(itemset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "silent-performer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1\n",
      "I2\n",
      "I3\n"
     ]
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/python-print-sublists-list/\n",
    "powerset = itemset[0]\n",
    "subset = []\n",
    "for i in range(len(powerset)):\n",
    "    orig = subset[:]\n",
    "    new=powerset[i]\n",
    "    print(new)\n",
    "    for j in range(len(subset)):\n",
    "        print(subset[j])\n",
    "        subset[j].append(new)\n",
    "    subset = orig + subset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "official-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/374626/how-can-i-find-all-the-subsets-of-a-set-with-exactly-n-elements\n",
    "import itertools\n",
    "def findsubsets(S,m):\n",
    "    return set(itertools.combinations(S, m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "tested-domain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('I1', 'I2'), ('I1', 'I3'), ('I2', 'I3')}"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findsubsets(itemset[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python-program-to-get-all-subsets-of-given-size-of-a-set/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "theoretical-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/18826571/python-powerset-of-a-given-set-with-generators\n",
    "#https://stackoverflow.com/questions/26332412/python-recursive-function-to-display-all-subsets-of-given-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "sized-doubt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "southern-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "print(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "liked-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.technomancy.org/python/powerset-generator-python/\n",
    "\n",
    "def powerset(seq):\n",
    "    \"\"\"\n",
    "    Returns all the subsets of this set. This is a generator.\n",
    "    \"\"\"\n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "        yield []\n",
    "    else:\n",
    "        for item in powerset(seq[1:]):\n",
    "            yield [seq[0]]+item\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "human-pickup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object powerset at 0x0000025F6E8C09E0>"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powerset(itemset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "indirect-muslim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['I1', 'I2'], dtype='<U2'),\n",
       " array(['I1', 'I3'], dtype='<U2'),\n",
       " array(['I2', 'I3'], dtype='<U2')]"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fp in ap.frequentPattern:\n",
    "    itemset = fp[0]\n",
    "    itemdict = fp[1]\n",
    "    print(itemset)\n",
    "    print(itemdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "cultural-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterItemsetwithCount(itemset,suppCountDict):\n",
    "    minSuppCount = 2\n",
    "    newItemset = []\n",
    "    counter = 1\n",
    "    for item in itemset:\n",
    "        count = suppCountDict[ap.getKey(item)]\n",
    "        if(count >= minSuppCount):\n",
    "            newItemset.append(item)\n",
    "    return np.array(newItemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "caroline-military",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beer' 'Bread' 'Cola' 'Diapers' 'Milk']\n",
      "1: Beer: 7\n",
      "2: Bread: 9\n",
      "3: Cola: 4\n",
      "4: Diapers: 6\n",
      "5: Milk: 8\n"
     ]
    }
   ],
   "source": [
    "newItem2 = filterItemsetwithCount(basicItem,itemDict)\n",
    "print(newItem2)\n",
    "ap.printItemsetCount(newItem2,itemDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "indoor-invite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Start of apriori ===========\n",
      "\n",
      "\n",
      "-------------- 1-itemset ---------------\n",
      "\n",
      "\n",
      "1: I1: 6\n",
      "2: I2: 7\n",
      "3: I3: 6\n",
      "4: I4: 2\n",
      "5: I5: 2\n",
      "\n",
      "\n",
      " Item that sastify min support count (3) \n",
      "\n",
      "\n",
      "1: I1: 6\n",
      "2: I2: 7\n",
      "3: I3: 6\n",
      "\n",
      "\n",
      "-------------- 2-itemset ---------------\n",
      "\n",
      "\n",
      "1: ['I1' 'I2']: 4\n",
      "2: ['I1' 'I3']: 4\n",
      "3: ['I2' 'I3']: 4\n",
      "\n",
      "\n",
      " Item that sastify min support count (3) \n",
      "\n",
      "\n",
      "1: ['I1' 'I2']: 4\n",
      "2: ['I1' 'I3']: 4\n",
      "3: ['I2' 'I3']: 4\n",
      "\n",
      "\n",
      "-------------- 3-itemset ---------------\n",
      "\n",
      "\n",
      "1: ['I1' 'I2' 'I3']: 2\n",
      "\n",
      "\n",
      " Item that sastify min support count (3) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============ End of apriori ============\n"
     ]
    }
   ],
   "source": [
    "file = 'item.csv'\n",
    "print ('{:=^40}'.format(f' Start of apriori '))\n",
    "ap = Apriori(3)\n",
    "ap.read_csv(file)\n",
    "ap.resolveDuplicated()\n",
    "frequentPattern = []\n",
    "\n",
    "basicItem = ap.basicItem\n",
    "itemDict = ap.getMinSupportItemset(basicItem)\n",
    "# print ('{:=^40}'.format(f' 1-itemset '))\n",
    "ap.displayStartDivider(1)\n",
    "ap.printItemsetCount(basicItem,itemDict)\n",
    "ItemFiltered = ap.filterItemsetwithCount(basicItem,itemDict)\n",
    "# print ('{}'.format(f' Item that sastify min support count ({ap.minSuppCount}) '))\n",
    "ap.displayMinSuppCountMsg()\n",
    "ap.printItemsetCount(ItemFiltered,itemDict)\n",
    "frequentPattern.append(ItemFiltered)\n",
    "counter = 2\n",
    "while ItemFiltered.size > 2:\n",
    "    ap.displayStartDivider(counter)\n",
    "#     print ('{:=^40}'.format(f' {counter}-itemset '))\n",
    "    nextItemset = ap.getNextItemset(ItemFiltered,counter)\n",
    "    nextItemsetCount = ap.getMinSupportItemset(nextItemset)\n",
    "    ap.printItemsetCount(nextItemset,nextItemsetCount)\n",
    "    ItemFiltered = ap.filterItemsetwithCount(nextItemset,nextItemsetCount)\n",
    "    ap.displayMinSuppCountMsg()\n",
    "    ap.printItemsetCount(ItemFiltered,nextItemsetCount)\n",
    "    counter = counter+1\n",
    "    if(ItemFiltered.size != 0):\n",
    "        frequentPattern.append(ItemFiltered)\n",
    "# print ('{:^40}'.format(f' None '))\n",
    "print('\\n')\n",
    "print ('{:=^40}'.format(f' End of apriori '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "interpreted-ordinance",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-530-f73df2a2cdd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfrequentPattern\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "frequentPattern[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "familiar-while",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1\n",
      "I2\n",
      "I3\n",
      "['I1' 'I2']\n",
      "['I1' 'I3']\n",
      "['I2' 'I3']\n"
     ]
    }
   ],
   "source": [
    "for itemset in frequentPattern:\n",
    "    for item in itemset:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "structured-dominant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicItemFiltered.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextItemset.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-appendix",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "automated-invalid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Beer: 7\n",
      "2: Bread: 9\n",
      "3: Cola: 4\n",
      "4: Diapers: 6\n",
      "5: Diapers1: 1\n",
      "6: Eggs: 1\n",
      "7: Milk: 8\n",
      "1: ['Beer' 'Bread']: 6\n",
      "2: ['Beer' 'Cola']: 3\n",
      "3: ['Beer' 'Diapers']: 5\n",
      "4: ['Beer' 'Milk']: 5\n",
      "5: ['Bread' 'Cola']: 3\n",
      "6: ['Bread' 'Diapers']: 5\n",
      "7: ['Bread' 'Milk']: 7\n",
      "8: ['Cola' 'Diapers']: 2\n",
      "9: ['Cola' 'Milk']: 4\n",
      "10: ['Diapers' 'Milk']: 4\n",
      "1: ['Beer' 'Bread' 'Cola']: 2\n",
      "2: ['Beer' 'Bread' 'Diapers']: 4\n",
      "3: ['Beer' 'Bread' 'Milk']: 4\n",
      "4: ['Beer' 'Cola' 'Diapers']: 1\n",
      "5: ['Beer' 'Cola' 'Milk']: 3\n",
      "6: ['Beer' 'Diapers' 'Milk']: 3\n",
      "7: ['Bread' 'Cola' 'Diapers']: 1\n",
      "8: ['Bread' 'Cola' 'Milk']: 3\n",
      "9: ['Bread' 'Diapers' 'Milk']: 3\n",
      "10: ['Cola' 'Diapers' 'Milk']: 2\n"
     ]
    }
   ],
   "source": [
    "file = 'food.csv'\n",
    "ap = Apriori()\n",
    "ap.read_csv(file)\n",
    "ap.resolveDuplicated()\n",
    "\n",
    "basicItem = ap.basicItem\n",
    "itemDict = ap.getMinSupportItemset(basicItem)\n",
    "ap.printItemsetCount(basicItem,itemDict)\n",
    "basicItemFiltered = ap.filterItemsetwithCount(basicItem,itemDict)\n",
    "\n",
    "item2Set = ap.getNextItemset(basicItemFiltered,2)\n",
    "item2Dict = ap.getMinSupportItemset(item2Set)\n",
    "ap.printItemsetCount(item2Set,item2Dict)\n",
    "item2SetFiltered = ap.filterItemsetwithCount(item2Set,item2Dict)\n",
    "\n",
    "item3Set = ap.getNextItemset(item2SetFiltered,3)\n",
    "item3Dict = ap.getMinSupportItemset(item3Set)\n",
    "ap.printItemsetCount(item3Set,item3Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "undefined-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "basicItemDict = ap.getMinSupportItemset(basicItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "greek-costume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Beer': 0, 'Bread': 0, 'Cola': 0, 'Diapers': 0, 'Diapers1': 0, 'Eggs': 0, 'Milk': 0}\n"
     ]
    }
   ],
   "source": [
    "print(basicItemDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "flush-geology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(basicItem[0]) == np.str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "dominant-teacher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(item2Set[0]) == np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "color-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'I\\x00\\x00\\x001\\x00\\x00\\x00I\\x00\\x00\\x002\\x00\\x00\\x00': 4, b'I\\x00\\x00\\x001\\x00\\x00\\x00I\\x00\\x00\\x003\\x00\\x00\\x00': 4, b'I\\x00\\x00\\x001\\x00\\x00\\x00I\\x00\\x00\\x004\\x00\\x00\\x00': 1, b'I\\x00\\x00\\x001\\x00\\x00\\x00I\\x00\\x00\\x005\\x00\\x00\\x00': 2, b'I\\x00\\x00\\x002\\x00\\x00\\x00I\\x00\\x00\\x003\\x00\\x00\\x00': 4, b'I\\x00\\x00\\x002\\x00\\x00\\x00I\\x00\\x00\\x004\\x00\\x00\\x00': 2, b'I\\x00\\x00\\x002\\x00\\x00\\x00I\\x00\\x00\\x005\\x00\\x00\\x00': 2, b'I\\x00\\x00\\x003\\x00\\x00\\x00I\\x00\\x00\\x004\\x00\\x00\\x00': 0, b'I\\x00\\x00\\x003\\x00\\x00\\x00I\\x00\\x00\\x005\\x00\\x00\\x00': 1, b'I\\x00\\x00\\x004\\x00\\x00\\x00I\\x00\\x00\\x005\\x00\\x00\\x00': 0}\n"
     ]
    }
   ],
   "source": [
    "print(itemDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "continental-angle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I1', 'I2', 'I3', 'I4', 'I5'], dtype=object)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(basicItem, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "elder-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(item2Set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "grand-horror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(basicItem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "racial-helmet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "newDict = defaultdict(list)\n",
    "suppCountDict = defaultdict(list)\n",
    "for item in item2Set:\n",
    "    suppCountDict[item.tobytes()]=(ap.calculateMinSuppCount(item))\n",
    "print(suppCountDict[item2Set[0].tobytes()])\n",
    "print(ap.calculateMinSuppCount(item2Set[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "written-worcester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I4' 'I5']\n"
     ]
    }
   ],
   "source": [
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "compound-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMinSupportItemset(basicItemSet):\n",
    "    suppCountDict = defaultdict(list)\n",
    "    for basicItem in basicItemSet:\n",
    "        suppCountDict[basicItem.tobytes()] = ap.calculateMinSuppCount(basicItem)\n",
    "    return suppCountDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "prescription-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdict = getMinSupportItemSet(item2Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "incident-electric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'I\\x00\\x00\\x001\\x00\\x00\\x00I\\x00\\x00\\x002\\x00\\x00\\x00': 4, b'I\\x00\\x00\\x001\\x00\\x00\\x00I\\x00\\x00\\x003\\x00\\x00\\x00': 4, b'I\\x00\\x00\\x001\\x00\\x00\\x00I\\x00\\x00\\x004\\x00\\x00\\x00': 1, b'I\\x00\\x00\\x001\\x00\\x00\\x00I\\x00\\x00\\x005\\x00\\x00\\x00': 2, b'I\\x00\\x00\\x002\\x00\\x00\\x00I\\x00\\x00\\x003\\x00\\x00\\x00': 4, b'I\\x00\\x00\\x002\\x00\\x00\\x00I\\x00\\x00\\x004\\x00\\x00\\x00': 2, b'I\\x00\\x00\\x002\\x00\\x00\\x00I\\x00\\x00\\x005\\x00\\x00\\x00': 2, b'I\\x00\\x00\\x003\\x00\\x00\\x00I\\x00\\x00\\x004\\x00\\x00\\x00': 0, b'I\\x00\\x00\\x003\\x00\\x00\\x00I\\x00\\x00\\x005\\x00\\x00\\x00': 1, b'I\\x00\\x00\\x004\\x00\\x00\\x00I\\x00\\x00\\x005\\x00\\x00\\x00': 0}\n"
     ]
    }
   ],
   "source": [
    "print(newdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "acquired-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMinSupportItemset(self,basicItemSet):\n",
    "    suppCountDict = {}\n",
    "    for basicItem in basicItemSet:\n",
    "        suppCountDict[basicItem.keys()] = self.calculateMinSuppCount(basicItem)\n",
    "    return suppCountDict\n",
    "\n",
    "def printItemsetCount(itemset,suppCountDict):\n",
    "    minSuppCount = 2\n",
    "    k = item2Set.shape[1]\n",
    "    print ('{:=^40}'.format(f' {k}-ItemSet '))\n",
    "    for item in itemset:\n",
    "        print(f'{item}: {suppCountDict[item.tobytes()]}')\n",
    "    print ('{}'.format(f' Item that sastify min support count ({minSuppCount}) '))\n",
    "    for item in itemset:\n",
    "        count = suppCountDict[item.tobytes()]\n",
    "        if(count >= minSuppCount):\n",
    "            print(f'{item}: {suppCountDict[item.tobytes()]}')\n",
    "    print ('{:=^40}'.format(f' End of {k}-ItemSet '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "historical-malpractice",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-242-5da433170289>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbasicItem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "basicItem[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "brave-amateur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== 2-ItemSet ===============\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "b'B\\x00\\x00\\x00e\\x00\\x00\\x00e\\x00\\x00\\x00r\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00B\\x00\\x00\\x00r\\x00\\x00\\x00e\\x00\\x00\\x00a\\x00\\x00\\x00d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-238-34ef0d43a6c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprintItemsetCount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem2Set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-237-80f8f1d7e596>\u001b[0m in \u001b[0;36mprintItemsetCount\u001b[1;34m(itemset, suppCountDict)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'{:=^40}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf' {k}-ItemSet '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitemset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{item}: {suppCountDict[item.tobytes()]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf' Item that sastify min support count ({minSuppCount}) '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitemset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: b'B\\x00\\x00\\x00e\\x00\\x00\\x00e\\x00\\x00\\x00r\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00B\\x00\\x00\\x00r\\x00\\x00\\x00e\\x00\\x00\\x00a\\x00\\x00\\x00d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'"
     ]
    }
   ],
   "source": [
    "printItemsetCount(item2Set,newdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fixed-bench",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(item2Set.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "living-proportion",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-2988608318d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem2Set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "len(newdict[item2Set[0].tobytes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "younger-obligation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I1' 'I2' 'I3' 'I4' 'I5']\n"
     ]
    }
   ],
   "source": [
    "print(basicItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "realistic-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNextBasicItem(basicItem, k):\n",
    "    newBasicItem = []\n",
    "    for n,item in enumerate(basicItem):\n",
    "        for j in range(n+1,len(basicItem)):\n",
    "            item1 = item\n",
    "            item2 = basicItem[j]\n",
    "            itemSet = np.union1d(item1,item2)\n",
    "            if(len(itemSet) == k):\n",
    "                newBasicItem.append(itemSet)\n",
    "        uniqueBasicItem = np.unique(np.array(newBasicItem),axis=0)\n",
    "        uniqueBasicItem.astype(object)\n",
    "    return uniqueBasicItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eleven-rental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['I1' 'I2' 'I3' 'I4'],4,<class 'numpy.ndarray'>\n",
      "['I1' 'I2' 'I3' 'I5'],4,<class 'numpy.ndarray'>\n",
      "['I1' 'I2' 'I4' 'I5'],4,<class 'numpy.ndarray'>\n",
      "['I1' 'I3' 'I4' 'I5'],4,<class 'numpy.ndarray'>\n",
      "['I2' 'I3' 'I4' 'I5'],4,<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "newBasicItem = []\n",
    "newBasicItem = getNextBasicItem(basicItem,2)\n",
    "new2BasicItem = getNextBasicItem(newBasicItem,3)\n",
    "new3BasicItem = getNextBasicItem(new2BasicItem,4)\n",
    "print(len(new3BasicItem))\n",
    "for item in new3BasicItem:\n",
    "    print(f'{item},{len(item)},{type(item)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "greater-template",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['I1', 'I2', 'I5', 'None'],\n",
       "       ['I2', 'I4', 'None', 'None'],\n",
       "       ['I2', 'I3', 'None', 'None'],\n",
       "       ['I1', 'I2', 'I4', 'None'],\n",
       "       ['I1', 'I3', 'None', 'None'],\n",
       "       ['I2', 'I3', 'None', 'None'],\n",
       "       ['I1', 'I3', 'None', 'None'],\n",
       "       ['I1', 'I2', 'I3', 'I5'],\n",
       "       ['I1', 'I2', 'I3', 'None']], dtype='<U4')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.rawSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "anonymous-fiber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I1', 'I2'], dtype='<U2')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newBasicItem[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# newDict = defaultdict(list)\n",
    "# for item in newBasicItem:\n",
    "#     itemIndexes = np.where(ap.rawSet == item)\n",
    "#     counter = 1\n",
    "#     for i in range(len(itemIndexes[0])):  \n",
    "#         x = itemIndexes[0][i]\n",
    "#         y = itemIndexes[1][i]\n",
    "#         newDict[item].append([x,y])\n",
    "# for item in newDict:\n",
    "#     print(f'{item}: {newDict[item]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = new2BasicItem[0]\n",
    "# print(item)\n",
    "# print(item.dtype)\n",
    "# output = repr(ap.rawSet).count(item)\n",
    "# print(itemIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.argwhere(item == ap.rawSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "willing-hygiene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Beer\n",
      "[0 1 1 1 0 0 1 1 1 1]\n",
      "[[False False False False]\n",
      " [False False  True False]\n",
      " [False False  True False]\n",
      " [False False False  True]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False  True False]\n",
      " [False False  True False]\n",
      " [False False False  True]\n",
      " [False False  True False]]\n",
      "[False False False False False False False False False False]\n",
      "(array([], dtype=int64),)\n",
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/56419519/selecting-rows-of-numpy-array-that-contains-all-the-given-values\n",
    "item = basicItem[0]\n",
    "print(len(item))\n",
    "print(item)\n",
    "mask = np.isin(ap.rawSet,item)\n",
    "print(mask.sum(axis=1))\n",
    "vec_mask = np.isin(mask.sum(axis=1), [len(item)])\n",
    "ids = np.where(vec_mask)\n",
    "existence = ap.rawSet[ids]\n",
    "print(mask)\n",
    "print(vec_mask)\n",
    "print(ids)\n",
    "print(existence)\n",
    "print(len(ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eligible-standing",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'item' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1c8d943f4285>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'item' is not defined"
     ]
    }
   ],
   "source": [
    "np.any(np.isin(ap.rawSet, item), axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "chubby-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_number_of_occurrences(needle, haystack):\n",
    "#     needle = tuple(needle)\n",
    "#     return len([straw for straw in haystack if tuple(straw) == needle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_number_of_occurrences(item == ap.rawSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "id": "decent-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy_indexed as npi\n",
    "# unique_rows, row_count = npi.count(ap.rawSet, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(unique_rows)):\n",
    "#     print(unique_rows[i],',',row_count[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "dm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
